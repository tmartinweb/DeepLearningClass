# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13tVEM8crv01N1mWaoNZLxcFGkVMiMhyF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

train = pd.read_csv('houses_dataset.csv')
train.SalePrice.describe()

"""#Next, we'll check for skewness"""

print ("Skew is:", train.SalePrice.skew())
plt.hist(train.SalePrice, color='blue')
plt.show()

"""#Working with Numeric Features

"""

numeric_features = train.select_dtypes(include=[np.number])
corr = numeric_features.corr()
print (corr['SalePrice'].sort_values(ascending=False)[:5], '\n')
print (corr['SalePrice'].sort_values(ascending=False)[-5:])
quality_pivot = train.pivot_table(index='OverallQual',
                                  values='SalePrice', aggfunc=np.median)
print(quality_pivot)

"""Notice that the median sales price strictly increases as Overall Quality increases.

"""

quality_pivot.plot(kind='bar', color='blue')
plt.xlabel('Overall Quality')
plt.ylabel('Median Sale Price')
plt.xticks(rotation=0)
plt.show()

"""##Null values

"""

nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])
nulls.columns = ['Null Count']
nulls.index.name = 'Feature'
print(nulls)

"""##handling missing value"""

data = train.select_dtypes(include=[np.number]).interpolate().dropna()
print(sum(data.isnull().sum() != 0))

data.describe()

"""#Wrangling the non-numeric Features"""

categoricals = train.select_dtypes(exclude=[np.number])
categoricals.describe()

"""Street column is categorical data

We need to convert it to be a numeric
"""

print(train.Street.value_counts, "\n")

"""# Complete the next steps from the ppt and save the file for the next step."""

from sklearn.preprocessing import LabelEncoder
for feature in categoricals:
  train[feature] = pd.Categorical(train[feature])
  train[feature] = train[feature].cat.codes

plt.scatter(train['SalePrice'], train['GarageArea'])
plt.title('SalePrice vs GarageArea')
plt.xlabel('Sale Price')
plt.ylabel('Garage Area')
plt.show()

from scipy import stats
z = np.abs(stats.zscore(train['GarageArea']))
drop_array = np.where(z > 3)
train.drop(drop_array[0],inplace=True)

plt.scatter(train['SalePrice'], train['GarageArea'])
plt.title('SalePrice vs GarageArea')
plt.xlabel('Sale Price')
plt.ylabel('Garage Area')
plt.show()

train.to_csv('houses_dataset_preprocessed.csv')



train.drop(columns=['Id'])
train = train.select_dtypes(include=[np.number]).interpolate().dropna()
y = np.log(train.pop('SalePrice'))
X = train

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=32)

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

print('R^2: ', model.score(X, y))

predictions = model.predict(X_test)

from sklearn import metrics as met
print('Mean Absolute Error:', met.mean_absolute_error(y_test, predictions))
print('Mean Squared Error:', met.mean_squared_error(y_test, predictions))
print('Root Mean Squared Error:', np.sqrt(met.mean_squared_error(y_test, predictions)))

plt.scatter(X_test['OverallQual'], y_test)
plt.title('SalePrice vs GarageArea')
plt.xlabel('Sale Price')
plt.ylabel('Garage Area')
m, b = np.polyfit(X_test['OverallQual'], y_test, 1)
plt.plot(X_test['OverallQual'], m*X_test['OverallQual'] + b)
plt.show()