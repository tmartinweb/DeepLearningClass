# -*- coding: utf-8 -*-
"""Lesson_6_Clustring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-F0cY1DyKmSO9VgNBh6L7EU43T9oAEYt
"""

from sklearn.cluster import KMeans
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

import seaborn as sns
sns.set(style="white", color_codes=True)
import warnings
warnings.filterwarnings("ignore")

x = pd.read_csv('CC.csv')

##Drop Cust_Id
x.drop(columns='CUST_ID', inplace=True)

##remove null/nans by mean
for column in x.columns:
    mean = x[column].mean()
    x[column].fillna(value=mean, inplace=True)


##find best number of clusters based on elbow method
wcss = []
for i in range(1,11):
    kmeans = KMeans(n_clusters=i, max_iter=300, random_state=32)
    kmeans.fit(x)
    wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Wcss')
plt.show()

##building the model
nclusters = 2 # this is the k in kmeans
km = KMeans(n_clusters=nclusters)
km.fit(x)

# predict the cluster for each data point
y_cluster_kmeans = km.predict(x)
from sklearn import metrics
score = metrics.silhouette_score(x, y_cluster_kmeans)
print(score)



## Standardize features
scaler = MinMaxScaler().fit(x)
x_scaled = pd.DataFrame(scaler.transform(x), columns=x.columns)

##find best number of clusters based on elbow method
wcss = []
for i in range(1,11):
    kmeans = KMeans(n_clusters=i, max_iter=300, random_state=32)
    kmeans.fit(x_scaled)
    wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Wcss')
plt.show()

##building the model
nclusters = 2 # this is the k in kmeans
km = KMeans(n_clusters=nclusters)
km.fit(x_scaled)

# predict the cluster for each data point
y_cluster_kmeans = km.predict(x_scaled)
from sklearn import metrics
score = metrics.silhouette_score(x_scaled, y_cluster_kmeans)
print(score)




## Standardize features
scaler = StandardScaler().fit(x)
x_scaled = pd.DataFrame(scaler.transform(x), columns=x.columns)


## PCA
pca = PCA(2)
X_pca = pd.DataFrame(pca.fit_transform(scaler.transform(x)))

##find best number of clusters based on elbow method
wcss = []
for i in range(1,11):
    kmeans = KMeans(n_clusters=i, max_iter=300, random_state=32)
    kmeans.fit(X_pca)
    wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Wcss')
plt.show()

##building the model
nclusters = 3 # this is the k in kmeans
km = KMeans(n_clusters=nclusters)
km.fit(X_pca)

# predict the cluster for each data point
y_cluster_kmeans = km.predict(X_pca)
from sklearn import metrics
score = metrics.silhouette_score(X_pca, y_cluster_kmeans)
print(score)

